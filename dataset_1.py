# -*- coding: utf-8 -*-
"""dataset_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10-gMr92D34BDqB265xPbi6ACmldRoJ6p
"""



# Data analysis libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Machine learning libraries
from sklearn import model_selection
from sklearn import metrics
from sklearn import ensemble
from sklearn import linear_model
from sklearn import tree
from sklearn import neighbors

# Read the CSV file and load it into a DataFrame
data = pd.read_csv('MELBOURNE_HOUSE_PRICES_LESS.csv')
data = pd.read_csv('Melbourne_housing_FULL.csv')

# Observe the first 5 columns
print("First 5 Columns of the Dataset:")
print(data.head())

# Find the shape, number of columns, and size of the dataset
shape = data.shape
num_columns = len(data.columns)
size = data.size

print("\nShape of the Dataset:", shape)
print("Number of Columns:", num_columns)
print("Size of the Dataset:", size)

# Display dataset information
print("\nDataset Information:")
data.info()

from scipy import stats

# Examine basic statistics
print(data.describe())

# Fill missing values with the mode of the column
data.fillna(data.mode().iloc[0], inplace=True)

# Check for duplicate data and remove duplicates
data.drop_duplicates(inplace=True)

# Define variables as categorical
data['CategoricalRooms'] = data['Rooms'].astype('category')
data['CategoricalType'] = data['Type'].astype('category')

# Review the final dataset
print("Final Dataset:")
print(data.head())

#Examine the descriptive statistics of dataset
descriptive_stats = data.describe()
print(descriptive_stats)

# Identify the categorical columns
categorical_columns = ['Type', 'Regionname', 'CouncilArea']

# Define the categorical variables in the dataset
data[categorical_columns] = data[categorical_columns].astype('category')

# Display information about the dataset
print(data.info())

# Check for duplicate data and remove duplicates
data = data.drop_duplicates()

# Display the updated dataset without duplicates
print(data)

# Calculate Z-scores for 'Landsize' and 'BuildingArea'
z_scores = np.abs(stats.zscore(data[['Landsize', 'BuildingArea']]))

# Set the Z-score threshold for identifying outliers
threshold = 3

# Create a mask to identify rows with outliers
outlier_mask = (z_scores > threshold).any(axis=1)

# Remove rows with outliers from the dataset
data = data[~outlier_mask]

# Display the updated dataset without outliers
print(data)

# Identify the categorical columns
categorical_columns = ['Type', 'Regionname', 'CouncilArea']

# Fill missing values in categorical columns with the mode
for column in categorical_columns:
    data[column].fillna(data[column].mode().iloc[0], inplace=True)

# Display the updated dataset with missing values filled
print(data)

# Extract the 'Price' column from the DataFrame
prices = data['Price']

# Create a histogram
plt.hist(prices, bins=20, color='blue', edgecolor='black')
plt.xlabel('Price')
plt.ylabel('Frequency')
plt.title('Price Distribution Histogram')
plt.show()

# Identify the categorical columns
categorical_columns = ['Type', 'Regionname', 'CouncilArea']

# Fill missing values in categorical columns with the mode
for column in categorical_columns:
    data[column].fillna(data[column].mode().iloc[0], inplace=True)

# Display the updated dataset with missing values filled
print(data)
